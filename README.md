# Sign-Language
The main objective of this project is to determine gesture recognition that might enable the deaf to converse with the hearing people remotely and is done by a JSON interpreter. We are not aware of any research which aim is to provide un-intermediated mobile communication between deaf and hearing people, each conversing using their own natural languages. Hence our project has provided the idea of implementing communication between deaf and hearing people in day-to-day life. Initially, mobile search functionality must recognize either ASL (American Sign Language) Text or voice and convert it to both text message as well as video for relevant input. ASL2TXT enable sign language finger spelling communication (signs displayed in the keyboard) take text and display video. 
